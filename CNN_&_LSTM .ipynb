{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4I3UGmf_BVBJ"
   },
   "source": [
    "CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "aS9gkOkPzUjN",
    "outputId": "47102eb0-d254-40c2-985a-45ca38d436d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>CIR</th>\n",
       "      <th>Mouth_EYE</th>\n",
       "      <th>label</th>\n",
       "      <th>Respondent</th>\n",
       "      <th>EAR_N</th>\n",
       "      <th>MAR_N</th>\n",
       "      <th>Circularity_N</th>\n",
       "      <th>MOE_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.284246</td>\n",
       "      <td>0.947518</td>\n",
       "      <td>0.482625</td>\n",
       "      <td>3.333446</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318166</td>\n",
       "      <td>-1.152166</td>\n",
       "      <td>3.818145</td>\n",
       "      <td>-1.250515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.292527</td>\n",
       "      <td>0.994375</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>3.399259</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.641281</td>\n",
       "      <td>-0.589006</td>\n",
       "      <td>3.883234</td>\n",
       "      <td>-1.071398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.267323</td>\n",
       "      <td>0.996076</td>\n",
       "      <td>0.449280</td>\n",
       "      <td>3.726111</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342113</td>\n",
       "      <td>-0.568555</td>\n",
       "      <td>2.139234</td>\n",
       "      <td>-0.181830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.350346</td>\n",
       "      <td>0.967453</td>\n",
       "      <td>0.534985</td>\n",
       "      <td>2.761419</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.897273</td>\n",
       "      <td>-0.912575</td>\n",
       "      <td>6.454395</td>\n",
       "      <td>-2.807358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.328317</td>\n",
       "      <td>0.988977</td>\n",
       "      <td>0.537504</td>\n",
       "      <td>3.012266</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.037727</td>\n",
       "      <td>-0.653878</td>\n",
       "      <td>6.581202</td>\n",
       "      <td>-2.124648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EAR       MAR       CIR  ...     MAR_N  Circularity_N     MOE_N\n",
       "0  0.284246  0.947518  0.482625  ... -1.152166       3.818145 -1.250515\n",
       "1  0.292527  0.994375  0.483918  ... -0.589006       3.883234 -1.071398\n",
       "2  0.267323  0.996076  0.449280  ... -0.568555       2.139234 -0.181830\n",
       "3  0.350346  0.967453  0.534985  ... -0.912575       6.454395 -2.807358\n",
       "4  0.328317  0.988977  0.537504  ... -0.653878       6.581202 -2.124648\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading total frames\n",
    "import pandas as pd\n",
    "df_total = pd.read_csv('/content/drive/My Drive/Total_frames/totalwithmaininfo.csv')\n",
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4hgvyQI0ean"
   },
   "outputs": [],
   "source": [
    "\n",
    "df_total.loc[(df_total['label'] == 10),'label'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "Hu_vIqwC-12u",
    "outputId": "8fa4e49a-a8d0-4d7e-fc29-bfae3cadc0e8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAR</th>\n",
       "      <th>MAR</th>\n",
       "      <th>CIR</th>\n",
       "      <th>Mouth_EYE</th>\n",
       "      <th>label</th>\n",
       "      <th>Respondent</th>\n",
       "      <th>EAR_N</th>\n",
       "      <th>MAR_N</th>\n",
       "      <th>Circularity_N</th>\n",
       "      <th>MOE_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.284246</td>\n",
       "      <td>0.947518</td>\n",
       "      <td>0.482625</td>\n",
       "      <td>3.333446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318166</td>\n",
       "      <td>-1.152166</td>\n",
       "      <td>3.818145</td>\n",
       "      <td>-1.250515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.292527</td>\n",
       "      <td>0.994375</td>\n",
       "      <td>0.483918</td>\n",
       "      <td>3.399259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.641281</td>\n",
       "      <td>-0.589006</td>\n",
       "      <td>3.883234</td>\n",
       "      <td>-1.071398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.267323</td>\n",
       "      <td>0.996076</td>\n",
       "      <td>0.449280</td>\n",
       "      <td>3.726111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.342113</td>\n",
       "      <td>-0.568555</td>\n",
       "      <td>2.139234</td>\n",
       "      <td>-0.181830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.350346</td>\n",
       "      <td>0.967453</td>\n",
       "      <td>0.534985</td>\n",
       "      <td>2.761419</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.897273</td>\n",
       "      <td>-0.912575</td>\n",
       "      <td>6.454395</td>\n",
       "      <td>-2.807358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.328317</td>\n",
       "      <td>0.988977</td>\n",
       "      <td>0.537504</td>\n",
       "      <td>3.012266</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.037727</td>\n",
       "      <td>-0.653878</td>\n",
       "      <td>6.581202</td>\n",
       "      <td>-2.124648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3835</th>\n",
       "      <td>0.155557</td>\n",
       "      <td>1.010112</td>\n",
       "      <td>0.313427</td>\n",
       "      <td>6.493502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.617024</td>\n",
       "      <td>5.267015</td>\n",
       "      <td>-17.886938</td>\n",
       "      <td>19.301433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3836</th>\n",
       "      <td>0.152062</td>\n",
       "      <td>1.018089</td>\n",
       "      <td>0.297301</td>\n",
       "      <td>6.695213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.844253</td>\n",
       "      <td>5.723550</td>\n",
       "      <td>-19.624125</td>\n",
       "      <td>20.380396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3837</th>\n",
       "      <td>0.158283</td>\n",
       "      <td>1.010600</td>\n",
       "      <td>0.323855</td>\n",
       "      <td>6.384763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.439820</td>\n",
       "      <td>5.294953</td>\n",
       "      <td>-16.763530</td>\n",
       "      <td>18.719781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3838</th>\n",
       "      <td>0.152245</td>\n",
       "      <td>1.045366</td>\n",
       "      <td>0.307941</td>\n",
       "      <td>6.866363</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-10.832399</td>\n",
       "      <td>7.284824</td>\n",
       "      <td>-18.477909</td>\n",
       "      <td>21.295892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3839</th>\n",
       "      <td>0.142766</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.299788</td>\n",
       "      <td>6.854790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-11.448600</td>\n",
       "      <td>3.465182</td>\n",
       "      <td>-19.356267</td>\n",
       "      <td>21.233986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3840 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           EAR       MAR       CIR  ...     MAR_N  Circularity_N      MOE_N\n",
       "0     0.284246  0.947518  0.482625  ... -1.152166       3.818145  -1.250515\n",
       "1     0.292527  0.994375  0.483918  ... -0.589006       3.883234  -1.071398\n",
       "2     0.267323  0.996076  0.449280  ... -0.568555       2.139234  -0.181830\n",
       "3     0.350346  0.967453  0.534985  ... -0.912575       6.454395  -2.807358\n",
       "4     0.328317  0.988977  0.537504  ... -0.653878       6.581202  -2.124648\n",
       "...        ...       ...       ...  ...       ...            ...        ...\n",
       "3835  0.155557  1.010112  0.313427  ...  5.267015     -17.886938  19.301433\n",
       "3836  0.152062  1.018089  0.297301  ...  5.723550     -19.624125  20.380396\n",
       "3837  0.158283  1.010600  0.323855  ...  5.294953     -16.763530  18.719781\n",
       "3838  0.152245  1.045366  0.307941  ...  7.284824     -18.477909  21.295892\n",
       "3839  0.142766  0.978632  0.299788  ...  3.465182     -19.356267  21.233986\n",
       "\n",
       "[3840 rows x 10 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "enUPqnkdzmd_",
    "outputId": "85e6467e-29f0-4e30-cf4e-2c77b91d90cb"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEJCAYAAABlmAtYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAT3UlEQVR4nO3df5Bd9Xnf8ffHApMmtgOOtlSWUERc2VNgUtnsYGrXHly3/JrUwh5KRRMjCBOZMST2TGcanHYGDykdpzXxGJJA5aIAKQVTExt1RglRaGKaNtisiMpPUy8YBmlkpCAPOCWmAZ7+cc/ia7G735W8994V9/2aObPnPufHPprZ4cM553u+N1WFJEnzecOoG5AkLX2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgYWFkmOS/InSR5J8nCST3b1tybZnuRb3c9junqSXJNkOskDSd7dd66N3f7fSrJxUD1LkmaXQb1nkWQFsKKq7k/yZmAHcA5wIbC/qj6b5HLgmKr61SRnA78MnA28B/hCVb0nyVuBKWASqO48J1fVdwfSuCTpNY4Y1Imrag+wp1v/XpJHgZXAeuC0brebgD8FfrWr31y99Lo3ydFd4JwGbK+q/QBJtgNnArfO9/uXL19ea9asWdx/lCS9ju3YseMvq2pitm0DC4t+SdYA7wK+DhzbBQnAd4Bju/WVwNN9h+3qanPV57VmzRqmpqZ+pL4laZwkeWqubQN/wJ3kTcAdwKeq6vn+bd1VxKLdB0uyKclUkql9+/Yt1mklaewNNCySHEkvKG6pqt/vys90t5dmnmvs7eq7geP6Dl/V1eaqv0ZVba6qyaqanJiY9UpKknQIBjkaKsANwKNV9Zt9m7YCMyOaNgJ39tUv6EZFnQo8192uugs4Pckx3cip07uaJGlIBvnM4n3Ax4AHk+zsar8GfBa4PcnFwFPAed22bfRGQk0DLwAXAVTV/iS/DtzX7XflzMNuSdJwDGzo7KhNTk6WD7glaeGS7Kiqydm2+Qa3JKnJsJAkNRkWkqQmw0KS1DSUN7gPR1O/csmoW9ASNHnN9aNuAYBL/peDN/Ra17931mfTi8IrC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUNLCySbEmyN8lDfbUvJdnZLU/OfDd3kjVJ/rpv2/V9x5yc5MEk00muSZJB9SxJmt0gpyi/Efgt4OaZQlX985n1JFcDz/Xt/3hVrZvlPNcBvwR8HdgGnAn8wQD6lSTNYWBXFlV1D7B/tm3d1cF5wK3znSPJCuAtVXVvVRW94DlnsXuVJM1vVM8s3g88U1Xf6qsdn+Qvknwtyfu72kpgV98+u7qaJGmIRvVNeefzw1cVe4DVVfVskpOBryY58WBPmmQTsAlg9erVi9KoJGkEVxZJjgA+CnxpplZVL1bVs936DuBx4B3AbmBV3+GrutqsqmpzVU1W1eTExMQg2peksTSK21D/GPhmVb16eynJRJJl3frPAGuBJ6pqD/B8klO75xwXAHeOoGdJGmuDHDp7K/DnwDuT7EpycbdpA699sP0B4IFuKO2XgUuqaubh+CeA/wRM07vicCSUJA3ZwJ5ZVNX5c9QvnKV2B3DHHPtPASctanOSpIPiG9ySpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktQ0yO/g3pJkb5KH+mqfSbI7yc5uObtv26eTTCd5LMkZffUzu9p0kssH1a8kaW6DvLK4EThzlvrnq2pdt2wDSHICsAE4sTvmd5IsS7IM+G3gLOAE4PxuX0nSEB0xqBNX1T1J1ixw9/XAbVX1IvDtJNPAKd226ap6AiDJbd2+jyxyu5KkeYzimcVlSR7oblMd09VWAk/37bOrq81VlyQN0bDD4jrg7cA6YA9w9WKePMmmJFNJpvbt27eYp5aksTbUsKiqZ6rq5ap6BfgiP7jVtBs4rm/XVV1trvpc599cVZNVNTkxMbG4zUvSGBtqWCRZ0ffxI8DMSKmtwIYkRyU5HlgLfAO4D1ib5Pgkb6T3EHzrMHuWJA3wAXeSW4HTgOVJdgFXAKclWQcU8CTwcYCqejjJ7fQeXL8EXFpVL3fnuQy4C1gGbKmqhwfVsyRpdoMcDXX+LOUb5tn/KuCqWerbgG2L2Jok6SD5BrckqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUNLCySbEmyN8lDfbX/kOSbSR5I8pUkR3f1NUn+OsnObrm+75iTkzyYZDrJNUkyqJ4lSbMb5JXFjcCZB9S2AydV1c8C/wf4dN+2x6tqXbdc0le/DvglYG23HHhOSdKADSwsquoeYP8BtT+qqpe6j/cCq+Y7R5IVwFuq6t6qKuBm4JxB9CtJmtson1n8IvAHfZ+PT/IXSb6W5P1dbSWwq2+fXV1NkjRER4zilyb518BLwC1daQ+wuqqeTXIy8NUkJx7CeTcBmwBWr169WO1K0tgb+pVFkguBnwN+vru1RFW9WFXPdus7gMeBdwC7+eFbVau62qyqanNVTVbV5MTExID+BZI0foYaFknOBP4V8OGqeqGvPpFkWbf+M/QeZD9RVXuA55Oc2o2CugC4c5g9S5IGeBsqya3AacDyJLuAK+iNfjoK2N6NgL23G/n0AeDKJH8DvAJcUlUzD8c/QW9k1d+i94yj/zmHJGkIBhYWVXX+LOUb5tj3DuCOObZNASctYmuSpIPkG9ySpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqSmBYVFkrsXUpMkvT7NO91Hkh8Dfpze/E7HADNfafoW/F4JSRobrbmhPg58CngbsIMfhMXzwG8NsC9J0hIyb1hU1ReALyT55aq6dkg9SZKWmAXNOltV1yZ5L7Cm/5iqunlAfUmSlpAFhUWS3wPeDuwEXu7KBRgWkjQGFvp9FpPACTNfgypJGi8Lfc/iIeDvDLIRSdLStdAri+XAI0m+Abw4U6yqDw+kK0nSkrLQsPjMoZw8yRbg54C9VXVSV3sr8CV6D8ufBM6rqu+m96XcXwDOBl4ALqyq+7tjNgL/pjvtv62qmw6lH0nSoVnQbaiq+tpsywIOvRE484Da5cDdVbUWuLv7DHAWsLZbNgHXwavhcgXwHuAU4IruBUFJ0pAsdLqP7yV5vlu+n+TlJM+3jquqe4D9B5TXAzNXBjcB5/TVb66ee4Gjk6wAzgC2V9X+qvousJ3XBpAkaYAW+p7Fm2fWu9tF64FTD/F3HltVe7r17wDHdusrgaf79tvV1eaqS5KG5KBnne3+z/+r9P6P/0fSDcVdtOG4STYlmUoytW/fvsU6rSSNvYW+lPfRvo9voPfexfcP8Xc+k2RFVe3pbjPt7eq7geP69lvV1XYDpx1Q/9PZTlxVm4HNAJOTk74TIkmLZKFXFv+0bzkD+B69W1GHYiuwsVvfCNzZV78gPacCz3W3q+4CTk9yTPdg+/SuJkkakoU+s7joUE6e5FZ6VwXLk+yiN6rps8DtSS4GngLO63bfRm/Y7DS9obMXdb97f5JfB+7r9ruyqg58aC5JGqCF3oZaBVwLvK8r/Q/gk1W1a77jqur8OTZ9aJZ9C7h0jvNsAbYspFdJ0uJb6G2o36V3m+ht3fLfupokaQwsNCwmqup3q+qlbrkRmBhgX5KkJWShYfFskl9IsqxbfgF4dpCNSZKWjoWGxS/SexD9HWAPcC5w4YB6kiQtMQudSPBKYGM33cbMfE2foxcikqTXuYVeWfzsTFBAbzgr8K7BtCRJWmoWGhZv6J/ptbuyWOhViSTpMLfQ/+BfDfx5kv/aff5nwFWDaUmStNQs9A3um5NMAf+oK320qh4ZXFuSpKVkwbeSunAwICRpDB30FOWSpPFjWEiSmgwLSVKTYSFJajIsJElNhoUkqcmwkCQ1GRaSpKahh0WSdybZ2bc8n+RTST6TZHdf/ey+Yz6dZDrJY0nOGHbPkjTuhj4ZYFU9BqwDSLIM2A18BbgI+HxVfa5//yQnABuAE+l9pesfJ3lHVb081MYlaYyN+jbUh4DHq+qpefZZD9xWVS9W1beBaeCUoXQnSQJGHxYbgFv7Pl+W5IEkW/qmRF8JPN23z66uJkkakpGFRZI3Ah8GZqY9vw54O71bVHvoTYt+sOfclGQqydS+ffsWrVdJGnejvLI4C7i/qp4BqKpnqurlqnoF+CI/uNW0Gziu77hVXe01qmpzVU1W1eTExMQAW5ek8TLKsDifvltQSVb0bfsI8FC3vhXYkOSoJMcDa4FvDK1LSdJovho1yU8A/wT4eF/53ydZBxTw5My2qno4ye30vkvjJeBSR0JJ0nCNJCyq6v8CP3VA7WPz7H8Vfo2rJI3MqEdDSZIOA4aFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVKTYSFJajIsJElNhoUkqWlkYZHkySQPJtmZZKqrvTXJ9iTf6n4e09WT5Jok00keSPLuUfUtSeNo1FcWH6yqdVU12X2+HLi7qtYCd3efAc4C1nbLJuC6oXcqSWNs1GFxoPXATd36TcA5ffWbq+de4OgkK0bRoCSNo1GGRQF/lGRHkk1d7diq2tOtfwc4tltfCTzdd+yuriZJGoIjRvi7/2FV7U7yt4HtSb7Zv7GqKkkdzAm70NkEsHr16sXrVJLG3MiuLKpqd/dzL/AV4BTgmZnbS93Pvd3uu4Hj+g5f1dUOPOfmqpqsqsmJiYlBti9JY2UkYZHkJ5K8eWYdOB14CNgKbOx22wjc2a1vBS7oRkWdCjzXd7tKkjRgo7oNdSzwlSQzPfyXqvrDJPcBtye5GHgKOK/bfxtwNjANvABcNPyWJWl8jSQsquoJ4O/PUn8W+NAs9QIuHUJrkqRZLLWhs5KkJciwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUNPSySHJfkT5I8kuThJJ/s6p9JsjvJzm45u++YTyeZTvJYkjOG3bMkjbtRfAf3S8C/rKr7k7wZ2JFke7ft81X1uf6dk5wAbABOBN4G/HGSd1TVy0PtWpLG2NCvLKpqT1Xd361/D3gUWDnPIeuB26rqxar6NjANnDL4TiVJM0b6zCLJGuBdwNe70mVJHkiyJckxXW0l8HTfYbuYP1wkSYtsZGGR5E3AHcCnqup54Drg7cA6YA9w9SGcc1OSqSRT+/btW9R+JWmcjSQskhxJLyhuqarfB6iqZ6rq5ap6BfgiP7jVtBs4ru/wVV3tNapqc1VNVtXkxMTE4P4BkjRmRjEaKsANwKNV9Zt99RV9u30EeKhb3wpsSHJUkuOBtcA3htWvJGk0o6HeB3wMeDDJzq72a8D5SdYBBTwJfBygqh5OcjvwCL2RVJc6EkqShmvoYVFVfwZklk3b5jnmKuCqgTUlSZqXb3BLkpoMC0lSk2EhSWoyLCRJTYaFJKnJsJAkNRkWkqQmw0KS1GRYSJKaDAtJUpNhIUlqMiwkSU2GhSSpybCQJDUZFpKkJsNCktRkWEiSmgwLSVLTYRMWSc5M8liS6SSXj7ofSRonh0VYJFkG/DZwFnACcH6SE0bblSSNj8MiLIBTgOmqeqKq/h9wG7B+xD1J0tg4XMJiJfB03+ddXU2SNARHjLqBxZRkE7Cp+/hXSR4bZT+vI8uBvxx1E0vCtf9x1B3otfz77CzCX+dPz7XhcAmL3cBxfZ9XdbUfUlWbgc3DampcJJmqqslR9yHNxr/P4ThcbkPdB6xNcnySNwIbgK0j7kmSxsZhcWVRVS8luQy4C1gGbKmqh0fcliSNjcMiLACqahuwbdR9jClv7Wkp8+9zCFJVo+5BkrTEHS7PLCRJI2RY6FWtKVWSHJXkS932rydZM/wuNY6SbEmyN8lDc2xPkmu6v80Hkrx72D2+3hkWAhY8pcrFwHer6u8Cnwd+Y7hdaozdCJw5z/azgLXdsgm4bgg9jRXDQjMWMqXKeuCmbv3LwIeSZIg9akxV1T3A/nl2WQ/cXD33AkcnWTGc7saDYaEZC5lS5dV9quol4Dngp4bSnTQ/pwQaMMNCktRkWGjGQqZUeXWfJEcAPwk8O5TupPktaEogHTrDQjMWMqXKVmBjt34u8N/LF3W0NGwFLuhGRZ0KPFdVe0bd1OvJYfMGtwZrrilVklwJTFXVVuAG4PeSTNN72LhhdB1rnCS5FTgNWJ5kF3AFcCRAVV1Pb3aHs4Fp4AXgotF0+vrlG9ySpCZvQ0mSmgwLSVKTYSFJajIsJElNhoUkqcmwkBZBkr9qbF8z14yp8xxzY5Jzf7TOpMVhWEiSmgwLaREleVOSu5Pcn+TBJP0z9x6R5JYkjyb5cpIf7445OcnXkuxIcpezpWopMiykxfV94CNV9W7gg8DVfdO4vxP4nar6e8DzwCeSHAlcC5xbVScDW4CrRtC3NC+n+5AWV4B/l+QDwCv0psk+ttv2dFX9z279PwO/AvwhcBKwvcuUZYBzGmnJMSykxfXzwARwclX9TZIngR/rth04t07RC5eHq+ofDK9F6eB5G0paXD8J7O2C4oPAT/dtW51kJhT+BfBnwGPAxEw9yZFJThxqx9ICGBbS4roFmEzyIHAB8M2+bY8BlyZ5FDgGuK77Cttzgd9I8r+BncB7h9yz1OSss5KkJq8sJElNhoUkqcmwkCQ1GRaSpCbDQpLUZFhIkpoMC0lSk2EhSWr6/wnHlGIJ3RGDAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the result column\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_total.label.value_counts()\n",
    "sns.countplot(x = 'label', data = df_total, palette = 'hls')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0IlFWItFzrqC"
   },
   "outputs": [],
   "source": [
    "#Diving the columns into dependent and independent columns\n",
    "X = df_total[['EAR','MAR','CIR','Mouth_EYE','EAR_N','MAR_N', 'Circularity_N', 'MOE_N']]\n",
    "Y = df_total['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ab6hOdSN0ax6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.20,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k2rFnDtt3iYf",
    "outputId": "172abb7f-e2e7-466d-c744-356fe520548f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072,)"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IYRqAjJJ1AEZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_train_shaped = np.expand_dims(X_train, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rL3NU30r1HTN",
    "outputId": "71be51a8-03fd-40ed-9a0d-dff1cc424d9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3072, 8, 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_shaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SuFC4-q-1Jxg"
   },
   "outputs": [],
   "source": [
    "X_test_shaped = np.expand_dims(X_test, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wt3J-Hrn1N5i",
    "outputId": "8e52ad1e-75f3-4123-8f2b-1211cc30328d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 8, 1)"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_shaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FFKOqGAV1TKq",
    "outputId": "b1666229-6927-48be-88e4-df812787a1cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3072 samples, validate on 768 samples\n",
      "Epoch 1/100\n",
      "3072/3072 [==============================] - 0s 97us/step - loss: 0.6538 - accuracy: 0.5088 - val_loss: 0.6695 - val_accuracy: 0.4727\n",
      "Epoch 2/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.6460 - accuracy: 0.5091 - val_loss: 0.6639 - val_accuracy: 0.4727\n",
      "Epoch 3/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.6411 - accuracy: 0.5225 - val_loss: 0.6587 - val_accuracy: 0.4727\n",
      "Epoch 4/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.6372 - accuracy: 0.5218 - val_loss: 0.6540 - val_accuracy: 0.4766\n",
      "Epoch 5/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.6360 - accuracy: 0.5306 - val_loss: 0.6497 - val_accuracy: 0.4779\n",
      "Epoch 6/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.6285 - accuracy: 0.5329 - val_loss: 0.6452 - val_accuracy: 0.4844\n",
      "Epoch 7/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.6259 - accuracy: 0.5511 - val_loss: 0.6407 - val_accuracy: 0.4922\n",
      "Epoch 8/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.6214 - accuracy: 0.5540 - val_loss: 0.6365 - val_accuracy: 0.5091\n",
      "Epoch 9/100\n",
      "3072/3072 [==============================] - 0s 55us/step - loss: 0.6178 - accuracy: 0.5739 - val_loss: 0.6319 - val_accuracy: 0.5547\n",
      "Epoch 10/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.6135 - accuracy: 0.6009 - val_loss: 0.6284 - val_accuracy: 0.5781\n",
      "Epoch 11/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.6107 - accuracy: 0.5999 - val_loss: 0.6245 - val_accuracy: 0.6029\n",
      "Epoch 12/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.6087 - accuracy: 0.6201 - val_loss: 0.6210 - val_accuracy: 0.6250\n",
      "Epoch 13/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.6039 - accuracy: 0.6452 - val_loss: 0.6168 - val_accuracy: 0.6484\n",
      "Epoch 14/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5992 - accuracy: 0.6579 - val_loss: 0.6138 - val_accuracy: 0.6549\n",
      "Epoch 15/100\n",
      "3072/3072 [==============================] - 0s 54us/step - loss: 0.5982 - accuracy: 0.6650 - val_loss: 0.6105 - val_accuracy: 0.6719\n",
      "Epoch 16/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5914 - accuracy: 0.6764 - val_loss: 0.6071 - val_accuracy: 0.6836\n",
      "Epoch 17/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.5928 - accuracy: 0.6807 - val_loss: 0.6044 - val_accuracy: 0.6862\n",
      "Epoch 18/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5881 - accuracy: 0.6868 - val_loss: 0.6018 - val_accuracy: 0.6888\n",
      "Epoch 19/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.5886 - accuracy: 0.6930 - val_loss: 0.5987 - val_accuracy: 0.6953\n",
      "Epoch 20/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5863 - accuracy: 0.6950 - val_loss: 0.5966 - val_accuracy: 0.7005\n",
      "Epoch 21/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5821 - accuracy: 0.6927 - val_loss: 0.5941 - val_accuracy: 0.7044\n",
      "Epoch 22/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.5827 - accuracy: 0.7025 - val_loss: 0.5910 - val_accuracy: 0.7083\n",
      "Epoch 23/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5762 - accuracy: 0.7044 - val_loss: 0.5884 - val_accuracy: 0.7122\n",
      "Epoch 24/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5741 - accuracy: 0.7077 - val_loss: 0.5860 - val_accuracy: 0.7174\n",
      "Epoch 25/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.5750 - accuracy: 0.7083 - val_loss: 0.5835 - val_accuracy: 0.7188\n",
      "Epoch 26/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5718 - accuracy: 0.7148 - val_loss: 0.5808 - val_accuracy: 0.7188\n",
      "Epoch 27/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5679 - accuracy: 0.7161 - val_loss: 0.5787 - val_accuracy: 0.7188\n",
      "Epoch 28/100\n",
      "3072/3072 [==============================] - 0s 54us/step - loss: 0.5666 - accuracy: 0.7249 - val_loss: 0.5760 - val_accuracy: 0.7227\n",
      "Epoch 29/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.5662 - accuracy: 0.7220 - val_loss: 0.5738 - val_accuracy: 0.7279\n",
      "Epoch 30/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.5668 - accuracy: 0.7220 - val_loss: 0.5716 - val_accuracy: 0.7305\n",
      "Epoch 31/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5644 - accuracy: 0.7321 - val_loss: 0.5690 - val_accuracy: 0.7318\n",
      "Epoch 32/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5588 - accuracy: 0.7298 - val_loss: 0.5666 - val_accuracy: 0.7331\n",
      "Epoch 33/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5563 - accuracy: 0.7344 - val_loss: 0.5645 - val_accuracy: 0.7344\n",
      "Epoch 34/100\n",
      "3072/3072 [==============================] - 0s 54us/step - loss: 0.5582 - accuracy: 0.7357 - val_loss: 0.5621 - val_accuracy: 0.7409\n",
      "Epoch 35/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5572 - accuracy: 0.7386 - val_loss: 0.5600 - val_accuracy: 0.7422\n",
      "Epoch 36/100\n",
      "3072/3072 [==============================] - 0s 58us/step - loss: 0.5527 - accuracy: 0.7409 - val_loss: 0.5585 - val_accuracy: 0.7422\n",
      "Epoch 37/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5500 - accuracy: 0.7454 - val_loss: 0.5560 - val_accuracy: 0.7409\n",
      "Epoch 38/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5507 - accuracy: 0.7396 - val_loss: 0.5543 - val_accuracy: 0.7409\n",
      "Epoch 39/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5489 - accuracy: 0.7409 - val_loss: 0.5522 - val_accuracy: 0.7435\n",
      "Epoch 40/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5439 - accuracy: 0.7396 - val_loss: 0.5503 - val_accuracy: 0.7448\n",
      "Epoch 41/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5474 - accuracy: 0.7399 - val_loss: 0.5487 - val_accuracy: 0.7435\n",
      "Epoch 42/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.5424 - accuracy: 0.7477 - val_loss: 0.5465 - val_accuracy: 0.7461\n",
      "Epoch 43/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5397 - accuracy: 0.7451 - val_loss: 0.5446 - val_accuracy: 0.7461\n",
      "Epoch 44/100\n",
      "3072/3072 [==============================] - 0s 54us/step - loss: 0.5374 - accuracy: 0.7471 - val_loss: 0.5430 - val_accuracy: 0.7500\n",
      "Epoch 45/100\n",
      "3072/3072 [==============================] - 0s 54us/step - loss: 0.5373 - accuracy: 0.7467 - val_loss: 0.5417 - val_accuracy: 0.7513\n",
      "Epoch 46/100\n",
      "3072/3072 [==============================] - 0s 54us/step - loss: 0.5409 - accuracy: 0.7461 - val_loss: 0.5399 - val_accuracy: 0.7513\n",
      "Epoch 47/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5410 - accuracy: 0.7461 - val_loss: 0.5386 - val_accuracy: 0.7526\n",
      "Epoch 48/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5362 - accuracy: 0.7422 - val_loss: 0.5367 - val_accuracy: 0.7552\n",
      "Epoch 49/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5292 - accuracy: 0.7523 - val_loss: 0.5350 - val_accuracy: 0.7526\n",
      "Epoch 50/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5347 - accuracy: 0.7464 - val_loss: 0.5335 - val_accuracy: 0.7539\n",
      "Epoch 51/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5304 - accuracy: 0.7454 - val_loss: 0.5316 - val_accuracy: 0.7539\n",
      "Epoch 52/100\n",
      "3072/3072 [==============================] - 0s 55us/step - loss: 0.5272 - accuracy: 0.7513 - val_loss: 0.5309 - val_accuracy: 0.7539\n",
      "Epoch 53/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5251 - accuracy: 0.7497 - val_loss: 0.5290 - val_accuracy: 0.7552\n",
      "Epoch 54/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.5256 - accuracy: 0.7487 - val_loss: 0.5275 - val_accuracy: 0.7578\n",
      "Epoch 55/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.5269 - accuracy: 0.7490 - val_loss: 0.5266 - val_accuracy: 0.7578\n",
      "Epoch 56/100\n",
      "3072/3072 [==============================] - 0s 49us/step - loss: 0.5229 - accuracy: 0.7428 - val_loss: 0.5249 - val_accuracy: 0.7591\n",
      "Epoch 57/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.5232 - accuracy: 0.7503 - val_loss: 0.5234 - val_accuracy: 0.7591\n",
      "Epoch 58/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.5212 - accuracy: 0.7523 - val_loss: 0.5230 - val_accuracy: 0.7604\n",
      "Epoch 59/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5231 - accuracy: 0.7467 - val_loss: 0.5217 - val_accuracy: 0.7617\n",
      "Epoch 60/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.5215 - accuracy: 0.7533 - val_loss: 0.5201 - val_accuracy: 0.7617\n",
      "Epoch 61/100\n",
      "3072/3072 [==============================] - 0s 48us/step - loss: 0.5210 - accuracy: 0.7526 - val_loss: 0.5190 - val_accuracy: 0.7617\n",
      "Epoch 62/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.5183 - accuracy: 0.7546 - val_loss: 0.5182 - val_accuracy: 0.7643\n",
      "Epoch 63/100\n",
      "3072/3072 [==============================] - 0s 49us/step - loss: 0.5138 - accuracy: 0.7542 - val_loss: 0.5173 - val_accuracy: 0.7630\n",
      "Epoch 64/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5187 - accuracy: 0.7520 - val_loss: 0.5163 - val_accuracy: 0.7630\n",
      "Epoch 65/100\n",
      "3072/3072 [==============================] - 0s 55us/step - loss: 0.5199 - accuracy: 0.7503 - val_loss: 0.5153 - val_accuracy: 0.7656\n",
      "Epoch 66/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.5170 - accuracy: 0.7568 - val_loss: 0.5139 - val_accuracy: 0.7630\n",
      "Epoch 67/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5156 - accuracy: 0.7562 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 68/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5192 - accuracy: 0.7487 - val_loss: 0.5123 - val_accuracy: 0.7643\n",
      "Epoch 69/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5128 - accuracy: 0.7578 - val_loss: 0.5115 - val_accuracy: 0.7643\n",
      "Epoch 70/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.5128 - accuracy: 0.7588 - val_loss: 0.5110 - val_accuracy: 0.7669\n",
      "Epoch 71/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5148 - accuracy: 0.7585 - val_loss: 0.5093 - val_accuracy: 0.7630\n",
      "Epoch 72/100\n",
      "3072/3072 [==============================] - 0s 55us/step - loss: 0.5133 - accuracy: 0.7552 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 73/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5119 - accuracy: 0.7565 - val_loss: 0.5079 - val_accuracy: 0.7643\n",
      "Epoch 74/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5084 - accuracy: 0.7575 - val_loss: 0.5068 - val_accuracy: 0.7669\n",
      "Epoch 75/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.5108 - accuracy: 0.7594 - val_loss: 0.5059 - val_accuracy: 0.7682\n",
      "Epoch 76/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5109 - accuracy: 0.7546 - val_loss: 0.5054 - val_accuracy: 0.7682\n",
      "Epoch 77/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.5069 - accuracy: 0.7546 - val_loss: 0.5047 - val_accuracy: 0.7682\n",
      "Epoch 78/100\n",
      "3072/3072 [==============================] - 0s 55us/step - loss: 0.5055 - accuracy: 0.7568 - val_loss: 0.5040 - val_accuracy: 0.7682\n",
      "Epoch 79/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.5083 - accuracy: 0.7591 - val_loss: 0.5037 - val_accuracy: 0.7682\n",
      "Epoch 80/100\n",
      "3072/3072 [==============================] - 0s 54us/step - loss: 0.5052 - accuracy: 0.7559 - val_loss: 0.5021 - val_accuracy: 0.7695\n",
      "Epoch 81/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.5057 - accuracy: 0.7510 - val_loss: 0.5016 - val_accuracy: 0.7695\n",
      "Epoch 82/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.5059 - accuracy: 0.7555 - val_loss: 0.5009 - val_accuracy: 0.7695\n",
      "Epoch 83/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5029 - accuracy: 0.7581 - val_loss: 0.4999 - val_accuracy: 0.7695\n",
      "Epoch 84/100\n",
      "3072/3072 [==============================] - 0s 54us/step - loss: 0.5027 - accuracy: 0.7539 - val_loss: 0.4994 - val_accuracy: 0.7695\n",
      "Epoch 85/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5004 - accuracy: 0.7572 - val_loss: 0.4990 - val_accuracy: 0.7682\n",
      "Epoch 86/100\n",
      "3072/3072 [==============================] - 0s 56us/step - loss: 0.5041 - accuracy: 0.7520 - val_loss: 0.4982 - val_accuracy: 0.7682\n",
      "Epoch 87/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.5056 - accuracy: 0.7572 - val_loss: 0.4971 - val_accuracy: 0.7721\n",
      "Epoch 88/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.4988 - accuracy: 0.7565 - val_loss: 0.4963 - val_accuracy: 0.7708\n",
      "Epoch 89/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.4979 - accuracy: 0.7578 - val_loss: 0.4960 - val_accuracy: 0.7695\n",
      "Epoch 90/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.5020 - accuracy: 0.7568 - val_loss: 0.4951 - val_accuracy: 0.7721\n",
      "Epoch 91/100\n",
      "3072/3072 [==============================] - 0s 52us/step - loss: 0.4988 - accuracy: 0.7542 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 92/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.5004 - accuracy: 0.7572 - val_loss: 0.4938 - val_accuracy: 0.7734\n",
      "Epoch 93/100\n",
      "3072/3072 [==============================] - 0s 53us/step - loss: 0.5013 - accuracy: 0.7552 - val_loss: 0.4938 - val_accuracy: 0.7695\n",
      "Epoch 94/100\n",
      "3072/3072 [==============================] - 0s 49us/step - loss: 0.5017 - accuracy: 0.7555 - val_loss: 0.4933 - val_accuracy: 0.7708\n",
      "Epoch 95/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.4970 - accuracy: 0.7607 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 96/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.4978 - accuracy: 0.7607 - val_loss: 0.4916 - val_accuracy: 0.7721\n",
      "Epoch 97/100\n",
      "3072/3072 [==============================] - 0s 51us/step - loss: 0.4954 - accuracy: 0.7581 - val_loss: 0.4911 - val_accuracy: 0.7708\n",
      "Epoch 98/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.4952 - accuracy: 0.7588 - val_loss: 0.4903 - val_accuracy: 0.7721\n",
      "Epoch 99/100\n",
      "3072/3072 [==============================] - 0s 50us/step - loss: 0.4973 - accuracy: 0.7598 - val_loss: 0.4903 - val_accuracy: 0.7708\n",
      "Epoch 100/100\n",
      "3072/3072 [==============================] - 0s 57us/step - loss: 0.4993 - accuracy: 0.7572 - val_loss: 0.4897 - val_accuracy: 0.7708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fc0ed2cd400>"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers import Dropout\n",
    "## Create Model ##\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, kernel_size = 3, activation = 'relu', input_shape = (8,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "## Compile Model ##\n",
    "optimizer = Adam(lr=0.00001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "## Train Model and Check Validation Accuracy ##\n",
    "model.fit(X_train_shaped, y_train, validation_data = (X_test_shaped,y_test), epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "vV5nLGJ41Vh-",
    "outputId": "77e16b98-412c-44d4-e028-cc0f2f6bf791"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 6, 64)             256       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 32)                12320     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 13,121\n",
      "Trainable params: 13,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "WF3MpbSY11a5",
    "outputId": "a1ac8d7d-ecd6-437b-db8e-79dca441e3fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7708333333333334]\n",
      "[[334  71]\n",
      " [105 258]]\n"
     ]
    }
   ],
   "source": [
    "#Finding Accuracy and Confusion Matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict_classes(X_test_shaped)\n",
    "accuracy = accuracy_score(y_test, np.array(y_pred))\n",
    "print([accuracy])\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NigWTq0tBZEx"
   },
   "source": [
    "LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTMI1EgBBteZ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_shaped_train  = np.array(X_train).reshape(512,6,8)\n",
    "x_shaped_test  = np.array(X_test).reshape(128,6,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "77iWjPApCWxB",
    "outputId": "8733cf38-796c-47af-dbe1-05d6364e0e4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "y_shaped_train  = []\n",
    "for i in range(0, len(y_train), 6):\n",
    "  y_shaped_train.append([y_train[i]])\n",
    "print(len(y_shaped_train))\n",
    "\n",
    "y_shaped_test  = []\n",
    "for i in range(0, len(y_test), 6):\n",
    "  y_shaped_test.append([y_test[i]])\n",
    "print(len(y_shaped_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "jwPKZZoLDJg4",
    "outputId": "d2104a19-5b00-400c-abfa-a8e8b4c08904"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 6, 8)"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shaped_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JcFC87wADNIk",
    "outputId": "51f491f2-142b-47c4-ab77-f923c5ebdee9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 6, 8)"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_shaped_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Iqi9E9UoDQzd",
    "outputId": "b4fabb8a-d69e-4ac8-d5ea-dd481cfe5fbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 1)"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_shaped_train = np.array(y_shaped_train)\n",
    "y_shaped_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I241i-BWDTjB",
    "outputId": "e775ee3a-185c-4c3c-8d8d-c54a2322a234"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 1)"
      ]
     },
     "execution_count": 127,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_shaped_test = np.array(y_shaped_test)\n",
    "y_shaped_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nmlMSTaCDXeb",
    "outputId": "d7f7baaf-ba61-4f1a-837d-0455d7754466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 512 samples, validate on 128 samples\n",
      "Epoch 1/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 3.2194 - accuracy: 0.3789 - val_loss: 0.7536 - val_accuracy: 0.5234\n",
      "Epoch 2/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 2.8149 - accuracy: 0.4395 - val_loss: 0.8228 - val_accuracy: 0.5234\n",
      "Epoch 3/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 2.7177 - accuracy: 0.4395 - val_loss: 0.6868 - val_accuracy: 0.5234\n",
      "Epoch 4/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 2.7176 - accuracy: 0.4238 - val_loss: 0.7107 - val_accuracy: 0.5234\n",
      "Epoch 5/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 2.7699 - accuracy: 0.4570 - val_loss: 0.7210 - val_accuracy: 0.5234\n",
      "Epoch 6/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 2.5233 - accuracy: 0.4648 - val_loss: 0.7999 - val_accuracy: 0.5234\n",
      "Epoch 7/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 2.1215 - accuracy: 0.5078 - val_loss: 0.7236 - val_accuracy: 0.5234\n",
      "Epoch 8/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 2.1506 - accuracy: 0.4629 - val_loss: 0.6841 - val_accuracy: 0.6328\n",
      "Epoch 9/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.9938 - accuracy: 0.4961 - val_loss: 0.7542 - val_accuracy: 0.5234\n",
      "Epoch 10/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 2.0765 - accuracy: 0.4688 - val_loss: 0.6858 - val_accuracy: 0.5234\n",
      "Epoch 11/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 2.1644 - accuracy: 0.4668 - val_loss: 0.6976 - val_accuracy: 0.5234\n",
      "Epoch 12/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.9849 - accuracy: 0.4883 - val_loss: 0.6911 - val_accuracy: 0.5234\n",
      "Epoch 13/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.8526 - accuracy: 0.4863 - val_loss: 0.7092 - val_accuracy: 0.5234\n",
      "Epoch 14/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.8519 - accuracy: 0.4941 - val_loss: 0.6932 - val_accuracy: 0.5234\n",
      "Epoch 15/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.9415 - accuracy: 0.5000 - val_loss: 0.6885 - val_accuracy: 0.5312\n",
      "Epoch 16/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.4477 - accuracy: 0.5156 - val_loss: 0.6820 - val_accuracy: 0.5781\n",
      "Epoch 17/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.8275 - accuracy: 0.4863 - val_loss: 0.6903 - val_accuracy: 0.5078\n",
      "Epoch 18/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.6542 - accuracy: 0.4629 - val_loss: 0.6867 - val_accuracy: 0.5547\n",
      "Epoch 19/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.4431 - accuracy: 0.4902 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 20/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.4233 - accuracy: 0.4824 - val_loss: 0.7077 - val_accuracy: 0.4766\n",
      "Epoch 21/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.5112 - accuracy: 0.4980 - val_loss: 0.7895 - val_accuracy: 0.4766\n",
      "Epoch 22/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.4820 - accuracy: 0.5254 - val_loss: 0.8470 - val_accuracy: 0.4766\n",
      "Epoch 23/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.4783 - accuracy: 0.4980 - val_loss: 0.6802 - val_accuracy: 0.5469\n",
      "Epoch 24/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.3766 - accuracy: 0.4746 - val_loss: 0.7043 - val_accuracy: 0.5234\n",
      "Epoch 25/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.3938 - accuracy: 0.4980 - val_loss: 0.7016 - val_accuracy: 0.4766\n",
      "Epoch 26/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.2226 - accuracy: 0.5039 - val_loss: 0.7726 - val_accuracy: 0.4766\n",
      "Epoch 27/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.1041 - accuracy: 0.5039 - val_loss: 0.7613 - val_accuracy: 0.4766\n",
      "Epoch 28/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.3196 - accuracy: 0.5430 - val_loss: 0.8210 - val_accuracy: 0.4766\n",
      "Epoch 29/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.6042 - accuracy: 0.4824 - val_loss: 0.7088 - val_accuracy: 0.5234\n",
      "Epoch 30/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.7264 - accuracy: 0.5234 - val_loss: 0.7145 - val_accuracy: 0.5234\n",
      "Epoch 31/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.8026 - accuracy: 0.4902 - val_loss: 1.3978 - val_accuracy: 0.5234\n",
      "Epoch 32/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 2.1219 - accuracy: 0.4863 - val_loss: 1.2297 - val_accuracy: 0.5234\n",
      "Epoch 33/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 1.9964 - accuracy: 0.4727 - val_loss: 0.9872 - val_accuracy: 0.5234\n",
      "Epoch 34/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.8795 - accuracy: 0.5000 - val_loss: 0.9514 - val_accuracy: 0.5234\n",
      "Epoch 35/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.5957 - accuracy: 0.5254 - val_loss: 0.7788 - val_accuracy: 0.5234\n",
      "Epoch 36/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.5630 - accuracy: 0.4883 - val_loss: 0.7606 - val_accuracy: 0.5234\n",
      "Epoch 37/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.4390 - accuracy: 0.4824 - val_loss: 0.7152 - val_accuracy: 0.5234\n",
      "Epoch 38/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.2355 - accuracy: 0.5000 - val_loss: 0.6821 - val_accuracy: 0.5312\n",
      "Epoch 39/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.3658 - accuracy: 0.4824 - val_loss: 0.6753 - val_accuracy: 0.5781\n",
      "Epoch 40/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.3962 - accuracy: 0.4941 - val_loss: 0.6879 - val_accuracy: 0.5234\n",
      "Epoch 41/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.7296 - accuracy: 0.5078 - val_loss: 0.6870 - val_accuracy: 0.5234\n",
      "Epoch 42/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.5306 - accuracy: 0.4941 - val_loss: 0.6806 - val_accuracy: 0.5312\n",
      "Epoch 43/50\n",
      "512/512 [==============================] - 6s 12ms/step - loss: 1.4172 - accuracy: 0.5039 - val_loss: 0.7204 - val_accuracy: 0.5234\n",
      "Epoch 44/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.5836 - accuracy: 0.5020 - val_loss: 0.6814 - val_accuracy: 0.5156\n",
      "Epoch 45/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.2298 - accuracy: 0.5254 - val_loss: 0.6815 - val_accuracy: 0.5547\n",
      "Epoch 46/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.0866 - accuracy: 0.5078 - val_loss: 0.7038 - val_accuracy: 0.5000\n",
      "Epoch 47/50\n",
      "512/512 [==============================] - 6s 13ms/step - loss: 1.3006 - accuracy: 0.5098 - val_loss: 0.7144 - val_accuracy: 0.4844\n",
      "Epoch 48/50\n",
      "512/512 [==============================] - 7s 13ms/step - loss: 1.2932 - accuracy: 0.5039 - val_loss: 0.7407 - val_accuracy: 0.4766\n",
      "Epoch 49/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 1.4197 - accuracy: 0.5039 - val_loss: 0.7022 - val_accuracy: 0.5234\n",
      "Epoch 50/50\n",
      "512/512 [==============================] - 7s 14ms/step - loss: 2.1086 - accuracy: 0.5098 - val_loss: 0.8238 - val_accuracy: 0.5234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "    MaxPooling2D)\n",
    "from collections import deque\n",
    "import sys\n",
    "\n",
    "metrics = ['accuracy']\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='sigmoid'))\n",
    "model.add(LSTM(512, return_sequences=True,\n",
    "                       input_shape=(5, 4,),\n",
    "                       dropout=0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "# Dense is fully connected layer. 16 hidden units\n",
    "# activation for lstm is basically sigmoid or tanh\n",
    "model.add(Dense(216, activation='sigmoid')) #FC1\n",
    "model.add(Dense(32, activation='tanh')) #FC2\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16, activation='relu'))#FC3\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='tanh'))#Output Layer\n",
    "optimizer = Adam(lr=0.00005)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=metrics)\n",
    "model.fit(x_shaped_train, y_shaped_train, validation_data = (x_shaped_test,y_shaped_test), epochs=50, batch_size=  10)\n",
    "model.predict_classes(x_shaped_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 459
    },
    "colab_type": "code",
    "id": "1vgsb-9ABSfC",
    "outputId": "5984d281-aa7f-4641-ea51-bbed695a7dba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 6, 1024)           9216      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 6, 512)            3147776   \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 216)               663768    \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                6944      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,828,249\n",
      "Trainable params: 3,828,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "utq8wvqgDhUn",
    "outputId": "992db961-e9a7-4bbc-f372-1029f72b8ec6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5234375]\n",
      "[[ 0 61]\n",
      " [ 0 67]]\n"
     ]
    }
   ],
   "source": [
    "#Finding Accuracy and Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred = model.predict_classes(x_shaped_test)\n",
    "acc = accuracy_score(y_shaped_test, y_pred)\n",
    "print([acc])\n",
    "print(confusion_matrix(y_shaped_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CNN & LSTM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
